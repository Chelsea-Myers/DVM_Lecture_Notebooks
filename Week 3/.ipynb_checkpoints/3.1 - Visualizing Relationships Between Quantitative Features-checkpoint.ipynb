{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the Relationships Between Quantitative Features\n",
    "\n",
    "So far we've looked at the distribution of single features, the distribution of two categorical features, and how to visualize differences between groups.  In this lesson we'll discuss how to look at the relationships between two quantitative features.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medical Cost Personal Dataset:\n",
    "\n",
    "How do personal features like age, BMI, smoking status and the region you live in effect how much you pay for healthcare?  The medical cost personal dataset shows the cost billed by health insurance companies for individuals based on their age, sex, BMI, number of children, smoking status, geographical region, and likelihood of an insurance claim.\n",
    "\n",
    "Do older people, in general, pay more for healthcare?  How do other factors like BMI and smoking effect your healthcare costs?  We'll find the answers to these questions in this lesson.\n",
    "\n",
    "Let's import pandas, matplotlib and seaborn and read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we are looking at the relationships between quantitative features.  Which three features are quantitative and continuous?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classic figure for examining the relationship between two quantitative features is called a scatterplot.  You've probably made them before.  We graph the value of one feature on the x-axis and the value of the other feature on the y-axis.  The pattern formed by the data tells us about the relationship between the two features.\n",
    "\n",
    "To start, we are going to graph the relationship between age (on the x-axis) and healthcare charges (on the y-axis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In general, we see that healthcare chargest tend to increase as people get older.  However, that relationship isn't perfect.  There appear to be three distinct groups in the scatterplot.  Also, within each group, a few people pay way more when they get old.  A few young people pay a lot.  Some people pay much less than everyone else.  However - in general - healthcare charges go up as age increases.\n",
    "\n",
    "Because the data points fall roughly in a line, we can represent the relationship between the two features with a linear model.  You'll talk a lot more about exactly how this works - how the model is fit to the data,how to tell if it's a good model or not, what to do about the fact that there appear to be three subgroups - in the machine learning course.\n",
    "\n",
    "Let's see if we can figure out - based on other features in the data - why there appear to be three distinct groups.  To do this, we can color-code the figure based on another feature.  Let's start with `claim_risk`.  Are some people paying more for healthcare because the insurance company has deemed them a higher claim risk?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That certainly seems to explain most of the differences.  Even still, there's a lot of variation within each group in healthcare costs for individuals of the same age.  Also, how did the insurance company come up with these risk categories?  Let's look at some other features.  Smoking, for example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That also seems to make a big impact.  The low risk, lowest cost group is comprised of all non-smokers, while the highest risk, highest cost group is comprised of all smokers.  The middle group contains both smokers and non-smokers.\n",
    "\n",
    "What about BMI?  We can also add color with our `hue=` feature is continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there's a mix of people with different BMIs in all three groups.\n",
    "\n",
    "It's not always the case that every feature in your data will be related to your target.  Let's look at patient sex.  Does that seem to impact how much the person will pay in healthcare costs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't appear to have an impact.  There are male and female patients represented in each of the three groups and they appear to be all mixed together.  There doesn't appear to be a pattern of male or female patients paying more for care at a particular age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "In data science, we are often interested in developing a model of our data.  A model is a mathematical representation of the general relationship present in our data.  \n",
    "\n",
    "**If the pattern of our data is roughly a line (either in the positive or negative direction) we can represent our data using a line - aka a linear model - aka linear regression.**  Because our data is clearly in three different groups, it makes sense to represent our data using three lines rather than one.  \n",
    "\n",
    "You'll learn much more about the ins and outs of this procedure, known as linear regression, in the machine learning course.  For now, it's enough to see a visual representation of using a model to summarize the relationship of age to healthcare costs for each group.  \n",
    "\n",
    "**Ideally your linear regression line should run right through the middle of your data, crossing as many points as possible.  There should be an approximately equal number of points above and below the regression line.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We couldn't use this model to perfectly predict the healthcare costs for an individual at a specific age.  However, if you were a healthcare economist, it could give you a ballpark figure how how much you expect costs to go up as people age depending on if they were at a low, medium or high claim risk.\n",
    "\n",
    "In the words of the famous statistician George Box (who is different from the boxplot guy, John Tukey):\n",
    "\n",
    "**\"All models are wrong, but some are useful.\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When is a line not a good fit for the data?\n",
    "\n",
    "Linear models are a powerful data analysis tool.  They do a great job in a lot of situations.  However, it's important to be on the lookout for times when a linear model is a poor fit for your data.  Making a visualization is often the easiest way to check for model fit issues ahead of time.\n",
    "\n",
    "A linear model is not a good fit for your data if:\n",
    "\n",
    "**1. Your data is made up of more than one distinct group.**\n",
    "\n",
    "One single line won't do a good job capturing the relationships for the individual groups.  Here the regression line passes through almost none of the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. When there are outliers that fall far outside the normal range of the data.**\n",
    "\n",
    "Here's an example plotting the relationship of age and fare paid in the Titanic data.  See those two people who were a little younger than 40 and paid 500 pounds for their tickets?  Those are outliers.  This model doesn't fit well because there are way more points above the line than below it, and there are big outliers at the top of the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**3. When there is a curved rather than linear relationship in the data.**\n",
    "\n",
    "Here is a plot of the cumulative revenue each week the film was showing.  You can see that the relationship of cumulative revenue to the number of weeks the film had been shown is curved rather than a straight line.  There are mathematical ways to transform a curved relationship into a straight line relationship, but we might not know one is present if we don't visualize the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# How to tackle nonlinear relationships\n",
    "\n",
    "This is something you'll dig into in much more detail in the machine learning class, but it's possible to model the relationship between two features with a non-linear relationship.\n",
    "Often this involves some trial and error on the part of the data scientist.  In this example, we look at modeling the relationship between temperature and quality in a manufacturing process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exponential Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "# Function to apply polynomial regression and plot results\n",
    "def apply_and_plot_polynomial_regression(degree, X_train, X_test, y_train, y_test):\n",
    "    # Create polynomial features\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "\n",
    "    # Fit a linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly, y_train)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    y_pred = model.predict(X_test_poly)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(X_train, y_train, alpha=0.5, color='darkgreen')\n",
    "    plt.scatter(X_test, y_test, alpha=0.5, color='darkgreen')\n",
    "    \n",
    "    # Plot the model\n",
    "    X_fit = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)\n",
    "    y_fit = model.predict(poly.transform(X_fit))\n",
    "    plt.plot(X_fit, y_fit, color='red', label=f'Polynomial Degree {degree} (R2: {r2:.2f})')\n",
    "\n",
    "    plt.title(f'Polynomial Regression (Degree {degree})')\n",
    "    plt.xlabel('Temperature (°C)')\n",
    "    plt.ylabel('Quality Rating')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return r2\n",
    "\n",
    "manufacturing_data = pd.read_csv('assets/manufacturing.csv', encoding='ISO-8859-1')\n",
    "manufacturing_data.rename(columns={'Temperature (Â°C)': 'Temperature (°C)'}, inplace=True)\n",
    "\n",
    "# Preparing the data\n",
    "X = manufacturing_data[['Temperature (°C)']].values\n",
    "y = manufacturing_data['Quality Rating'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Apply and plot polynomial regression for different degrees\n",
    "degrees = [2, 3, 4, 5]\n",
    "for degree in degrees:\n",
    "    apply_and_plot_polynomial_regression(degree, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logarithmic Relationship\n",
    "\n",
    "In this example, we look at the relationship between the carat value and cost of a diamond.\n",
    "\n",
    "Before log transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the diamonds dataset\n",
    "diamonds = sns.load_dataset('diamonds')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x = 'carat', y='price', data=diamonds)\n",
    "plt.title('Carat vs. Price')\n",
    "plt.xlabel('Carat')\n",
    "plt.ylabel('Price')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with log transformations to find the best linear relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carat vs log of price\n",
    "\n",
    "diamonds['log_carat'] = np.log(diamonds['carat'])\n",
    "diamonds['log_price'] = np.log(diamonds['price'])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x = 'carat', y='log_price', data=diamonds)\n",
    "plt.title('Carat vs. Log(Price)')\n",
    "plt.xlabel('Carat')\n",
    "plt.ylabel('Log(Price)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Price vs log of carat\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x = 'log_carat', y='price', data=diamonds)\n",
    "plt.title('Log(Carat) vs. Price')\n",
    "plt.xlabel('Log(Carat)')\n",
    "plt.ylabel('Price')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Both log transformed\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x = 'log_carat', y='log_price', data=diamonds)\n",
    "plt.title('Log(Carat) vs. Log(Price)')\n",
    "plt.xlabel('Log(Carat)')\n",
    "plt.ylabel('Log(Price)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# OK\n",
    "With these tools you should be able to visualize the relationship between two quantitative features and determine if other featuers in your dataset impact that relationship.  You can determine if a linear model is a good fit for the data by making a regression plot using Seaborn."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
